{
    "docs": [
        {
            "location": "/",
            "text": "SUMMIT Documentation \n\n\n\n Quick start \n\n\n\n\n\nSetting up SUMMIT\n \n\n\nRunning SUMMIT\n \n\n\n\n\n Building from source \n\n\n\n\n\nBuilding SUMMIT\n\n\n\n\n Programming Tutorials \n\n\n\n\n\nLoading and spawning maps\n\n\nNavigating on roads and sidewalks\n\n\n\n\n Advanced topics \n\n\n\n\n\nPreparing maps\n\n\nSimulating traffic\n\n\nConfiguring the simulation",
            "title": "Home"
        },
        {
            "location": "/getting_started/introduction/",
            "text": "SUMMIT\n\n\nSUMMIT (\nS\nimulator for \nU\nrban Driving \ni\nn \nM\nassive \nMi\nxed \nT\nraffic) is an open-source simulator with a focus on generating high-fidelity, interactive data for unregulated, dense urban traffic on complex real-world maps. It works with map data in the form of \nOSM files\n and \nSUMO networks\n to generate crowds of heterogeneous traffic agents with sophisticated and realistic unregulated behaviors. SUMMIT can work with map data fetched from online sources, providing a virtually unlimited source of complex environments.\n\n\nSUMMIT additionally exposes interfaces to interact with the contextual information provided by the map data. It also provides a robust suite of geometric utilities for use by external programs. Through these, SUMMIT aims to enablie applications in a wide range of fields such as perception, vehicle control and planning, end-to-end learning, etc. \n\n\nSUMMIT was built upon the very successful \nCARLA\n. Updates to CARLA are constantly merged into SUMMIT to ensure that users of SUMMIT have access to the high quality of work endowed by CARLA, such as its high-fidelity physics, rendering and sensors; however, it should be noted that not all components of SUMMIT work with those from CARLA, as they were designed for a different use case.\n\n\nThe simulator\n\n\nSUMMIT adds on top of CARLA a set of capabilities to enable the simulation of sophisticated traffic behaviors on real-world maps:\n\n\n\n\nRoad contexts: \n In SUMMIT, the \nSumoNetwork\n interface is exposed to allow for easy interaction with roads, which are represented using \nSUMO networks\n. It is optimized for fast spatial and topological queries.\n\n\nSidewalk contexts: \n Sidewalks are represented using a collection of oriented polygons with holes. SUMMIT exposes the \nSidewalk\n interface to easily interact with sidewalks. It is optimized for fast spatial and topological queries. Sidewalks are automatically generated as boundaries along roads.\n\n\nGeometric utilities: \n SUMMIT provides a range of utility classes to help with various geometric operations.\n\n\nOccupancyMap\n: Manipulation for general 2D areas. Useful for exact collision detection. \n\n\nAABBMap\n: Manipulation for axis aligned bounding boxes. Useful for fast approximate collision detection. \n\n\nSegmentsMap\n: Maipulation for collections of 2D line segments. Primarily used to sample high quality uniformly distributed spawn points on roads and sidewalks.\n\n\n\n\n\n\nProcedural simulation:\n Spawning a scenario is entirely procedural, and no recompilation the simulator is required for simulation on a new map. Mesh information for map objects such as roads, sidewalks, landmarks, and satellite imagery are sent from the client to the simulation server, where the objects are dynamically spawned.\n\n\nCrowd simulator:\n SUMMIT provides a client side Python script that simulates unregulated traffic in the simulation. It is capable of generating dense crowds, involving vehicles on the road and pedestrians on the sidewalk, where agents operate interactively with one another. \nGAMMA\n, a state-of-the-art traffic motion prediction model, is used to produce sophisticated and realistic behaviors in the simulated crowd.\n\n\n\n\nDriving expert\n\n\nWe also provide a driving expert using POMDP planning (as presented in the paper) and ROS-based communication. The planner is located on \nthis GitHub repo\n.",
            "title": "Introduction"
        },
        {
            "location": "/getting_started/introduction/#summit",
            "text": "SUMMIT ( S imulator for  U rban Driving  i n  M assive  Mi xed  T raffic) is an open-source simulator with a focus on generating high-fidelity, interactive data for unregulated, dense urban traffic on complex real-world maps. It works with map data in the form of  OSM files  and  SUMO networks  to generate crowds of heterogeneous traffic agents with sophisticated and realistic unregulated behaviors. SUMMIT can work with map data fetched from online sources, providing a virtually unlimited source of complex environments.  SUMMIT additionally exposes interfaces to interact with the contextual information provided by the map data. It also provides a robust suite of geometric utilities for use by external programs. Through these, SUMMIT aims to enablie applications in a wide range of fields such as perception, vehicle control and planning, end-to-end learning, etc.   SUMMIT was built upon the very successful  CARLA . Updates to CARLA are constantly merged into SUMMIT to ensure that users of SUMMIT have access to the high quality of work endowed by CARLA, such as its high-fidelity physics, rendering and sensors; however, it should be noted that not all components of SUMMIT work with those from CARLA, as they were designed for a different use case.",
            "title": "SUMMIT"
        },
        {
            "location": "/getting_started/introduction/#the-simulator",
            "text": "SUMMIT adds on top of CARLA a set of capabilities to enable the simulation of sophisticated traffic behaviors on real-world maps:   Road contexts:   In SUMMIT, the  SumoNetwork  interface is exposed to allow for easy interaction with roads, which are represented using  SUMO networks . It is optimized for fast spatial and topological queries.  Sidewalk contexts:   Sidewalks are represented using a collection of oriented polygons with holes. SUMMIT exposes the  Sidewalk  interface to easily interact with sidewalks. It is optimized for fast spatial and topological queries. Sidewalks are automatically generated as boundaries along roads.  Geometric utilities:   SUMMIT provides a range of utility classes to help with various geometric operations.  OccupancyMap : Manipulation for general 2D areas. Useful for exact collision detection.   AABBMap : Manipulation for axis aligned bounding boxes. Useful for fast approximate collision detection.   SegmentsMap : Maipulation for collections of 2D line segments. Primarily used to sample high quality uniformly distributed spawn points on roads and sidewalks.    Procedural simulation:  Spawning a scenario is entirely procedural, and no recompilation the simulator is required for simulation on a new map. Mesh information for map objects such as roads, sidewalks, landmarks, and satellite imagery are sent from the client to the simulation server, where the objects are dynamically spawned.  Crowd simulator:  SUMMIT provides a client side Python script that simulates unregulated traffic in the simulation. It is capable of generating dense crowds, involving vehicles on the road and pedestrians on the sidewalk, where agents operate interactively with one another.  GAMMA , a state-of-the-art traffic motion prediction model, is used to produce sophisticated and realistic behaviors in the simulated crowd.",
            "title": "The simulator"
        },
        {
            "location": "/getting_started/introduction/#driving-expert",
            "text": "We also provide a driving expert using POMDP planning (as presented in the paper) and ROS-based communication. The planner is located on  this GitHub repo .",
            "title": "Driving expert"
        },
        {
            "location": "/getting_started/setting_up/",
            "text": "Setting up SUMMIT\n\n\n\nRequirements\n\n\nThe requirements from SUMMIT derive from those of CARLA. Please ensure that you have met the \nrequirements of CARLA\n in order to use SUMMIT. \n\n\n\n\nImportant\n\n\n(As an exception, \nSUMMIT only supports Linux\n, and we do not have any foreseeable plans to extend support for Windows or macOS)\n\n\n\n\nIn addition, we make use of a few additional packages, as listed below.\n\n\n\n\nPython 2 packages: \npip2 install --user pathlib2 Pyro4\n\n\nPython 3 packages: \npip3 install --user pathlib Pyro4\n\n\n(Optional) \nJOSM\n: A set of tools to edit to downloaded OSM files. Highly recommended if you intend to use your own maps. If so, we recommend that you familiarize yourself with JOSM's usage.\n\n\n(Optional) \nSUMO tools\n: A set of tools to convert OSM files into SUMO networks, and to edit SUMO networks. Highly recommended if you intend to use your own maps. If so, we also recommend that you familiarize yourself with the usage of SUMO's tools, in particular \nNETCONVERT\n and \nNETEDIT\n.\n\n\n\n\nDownloading SUMMIT\n\n\nDownload the latest SUMMIT package from the \ndownloads page\n, and extract the contents somewhere of your preference.",
            "title": "Setting up SUMMIT"
        },
        {
            "location": "/getting_started/setting_up/#requirements",
            "text": "The requirements from SUMMIT derive from those of CARLA. Please ensure that you have met the  requirements of CARLA  in order to use SUMMIT.    Important  (As an exception,  SUMMIT only supports Linux , and we do not have any foreseeable plans to extend support for Windows or macOS)   In addition, we make use of a few additional packages, as listed below.   Python 2 packages:  pip2 install --user pathlib2 Pyro4  Python 3 packages:  pip3 install --user pathlib Pyro4  (Optional)  JOSM : A set of tools to edit to downloaded OSM files. Highly recommended if you intend to use your own maps. If so, we recommend that you familiarize yourself with JOSM's usage.  (Optional)  SUMO tools : A set of tools to convert OSM files into SUMO networks, and to edit SUMO networks. Highly recommended if you intend to use your own maps. If so, we also recommend that you familiarize yourself with the usage of SUMO's tools, in particular  NETCONVERT  and  NETEDIT .",
            "title": "Requirements"
        },
        {
            "location": "/getting_started/setting_up/#downloading-summit",
            "text": "Download the latest SUMMIT package from the  downloads page , and extract the contents somewhere of your preference.",
            "title": "Downloading SUMMIT"
        },
        {
            "location": "/getting_started/building/",
            "text": "Building SUMMIT\n\n\n\n\n\nImportant\n\n\nBuilding SUMMIT is only necessary if you wish to edit SUMMIT. If you only wish to use the simulator, the \nsetup steps\n are sufficient.\n\n\n\n\nThe build instructions for SUMMIT are exactly the same as those in CARLA. \n\n\nTo build SUMMIT, follow exactly the \nbuild instructions for CARLA\n, with some additional steps:\n\n\n\n\nClone and use the \nSUMMIT repository\n instead of the CARLA repository.\n\n\nBefore building SUMMIT\n, install \nccache\n: \nsudo apt install ccache\n.\n\n\nAfter getting assets\n, copy the following SUMMIT specific assets into the assets folder, overriding any existing files:\n\n\nCopy \n<summit_root>/CustomAssets/EmptyMap.umap\n to \n<summit_root>/Unreal/CarlaUE4/Content/Carla/Maps/TestMaps/EmptyMap.umap\n\n\nCopy \n<summit_root>/CustomAssets/EmptyMap_BuiltData.umap\n to \n<summit_root>/Unreal/CarlaUE4/Content/Carla/Maps/TestMaps/EmptyMap_BuiltData.umap\n\n\nCopy \n<summit_root>/CustomAssets/M_Tile.uasset\n to \n<summit_root>/Unreal/CarlaUE4/Content/Carla/Static/GenericMaterials/Ground/M_Tile.uasset",
            "title": "Building SUMMIT"
        },
        {
            "location": "/getting_started/running/",
            "text": "Running SUMMIT \n\n\n\nLaunching simulator\n\n\n\n\nImportant\n\n\nYou should have SUMMIT setup before running. To install SUMMIT, follow the \nsetting up steps\n.\n\n\n\n\nOpen a terminal in the folder where SUMMIT was extracted, and run \n./CarleUE4.sh\n to start the simulator. A window will open, containing an empty map. \n\n\n\n\nNote\n\n\nIf you get an X Error when running the simulator, try \n./CarlaUE4.sh -opengl\n instead.\n\n\n\n\nThe simulator is now running as a server, waiting for client apps to connect and to interact (e.g. spawning map objects dynamically, simulating a crowd, etc.) with it. \n\n\nRunning an example scenario\n\n\nHere, we provide a walkthrough of how to use SUMMIT to run a simple scenario, to showcase the various features of SUMMIT. \n\n\nYou will spawn a map of Meskel Square, one of SUMMIT's \nbuilt-in maps\n. Next, you will spawn a heterogeneous crowd on the map. Finally, you will run a sample agent, which attempts to navigate through the crowd.\n\n\nFirstly, spawn the Meskel Square map using the built-in \nspawn_meshes.py\n and \nspawn_imagery.py\n scripts. This will spawn the meshes and imagery relevant to Meskel Square:\n\n\n<summit_root>/PythonAPI/examples/spawn_meshes.py --dataset meskel_square\n<summit_root>/PythonAPI/examples/spawn_imagery.py --dataset meskel_square\n\n\n\n\nSecondly, spawn a heterogeneous crowd on the map using the built-in \ngamma_crowd.py\n script. This will simulate a heterogeneous traffic on the spawned map:\n\n\n<summit_root>/PythonAPI/examples/gamma_crowd.py --dataset meskel_square\n\n\n\n\nFinally, run the built-in sample \nmeskel_square_ego_vehicle.py\n script. This will spawn an agent that navigates through the crowd.\n\n\n<summit_root>/PythonAPI/examples/meskel_square_ego_vehicle.py\n\n\n\n\nWhat's next?\n\n\nTo get started writing your own scripts to interact with SUMMIT, you may step through the programming tutorials:\n\n\n\n\nLoad and spawn existing maps\n\n\nUsing roads and sidewalks\n\n\n\n\nTo learn how to prepare your own maps, or to read more about how to use the built-in traffic simulator, you may step through the map tutorials:\n\n\n\n\nPrepare new maps\n\n\nSimulate traffic in new maps\n\n\nConfiguring the simulation\n\n\n\n\nTo use the expert planner, check out our \nContext-POMDP repository\n.",
            "title": "Running SUMMIT"
        },
        {
            "location": "/getting_started/running/#launching-simulator",
            "text": "Important  You should have SUMMIT setup before running. To install SUMMIT, follow the  setting up steps .   Open a terminal in the folder where SUMMIT was extracted, and run  ./CarleUE4.sh  to start the simulator. A window will open, containing an empty map.    Note  If you get an X Error when running the simulator, try  ./CarlaUE4.sh -opengl  instead.   The simulator is now running as a server, waiting for client apps to connect and to interact (e.g. spawning map objects dynamically, simulating a crowd, etc.) with it.",
            "title": "Launching simulator"
        },
        {
            "location": "/getting_started/running/#running-an-example-scenario",
            "text": "Here, we provide a walkthrough of how to use SUMMIT to run a simple scenario, to showcase the various features of SUMMIT.   You will spawn a map of Meskel Square, one of SUMMIT's  built-in maps . Next, you will spawn a heterogeneous crowd on the map. Finally, you will run a sample agent, which attempts to navigate through the crowd.  Firstly, spawn the Meskel Square map using the built-in  spawn_meshes.py  and  spawn_imagery.py  scripts. This will spawn the meshes and imagery relevant to Meskel Square:  <summit_root>/PythonAPI/examples/spawn_meshes.py --dataset meskel_square\n<summit_root>/PythonAPI/examples/spawn_imagery.py --dataset meskel_square  Secondly, spawn a heterogeneous crowd on the map using the built-in  gamma_crowd.py  script. This will simulate a heterogeneous traffic on the spawned map:  <summit_root>/PythonAPI/examples/gamma_crowd.py --dataset meskel_square  Finally, run the built-in sample  meskel_square_ego_vehicle.py  script. This will spawn an agent that navigates through the crowd.  <summit_root>/PythonAPI/examples/meskel_square_ego_vehicle.py",
            "title": "Running an example scenario"
        },
        {
            "location": "/getting_started/running/#whats-next",
            "text": "To get started writing your own scripts to interact with SUMMIT, you may step through the programming tutorials:   Load and spawn existing maps  Using roads and sidewalks   To learn how to prepare your own maps, or to read more about how to use the built-in traffic simulator, you may step through the map tutorials:   Prepare new maps  Simulate traffic in new maps  Configuring the simulation   To use the expert planner, check out our  Context-POMDP repository .",
            "title": "What's next?"
        },
        {
            "location": "/tutorials/loading_and_spawning_maps/",
            "text": "Loading and Spawning Maps\n\n\n\n\n\nImportant\n\n\nSUMMIT comes with scripts that spawn all relevant map objects covered in this tutorial. You may use it directly them \n<summit_root>/PythonAPI/examples/spawn_meshes.py\n and \n<summit_root>/PythonAPI/examples/spawn_imagery.py\n, without going through this tutorial.\n\n\nNote that these scripts require that you have already \ncached the map object meshes\n and \ndownloaded the satellite imagery\n. For built-in SUMMIT maps, these have already been done for you, so you may go ahead with using the scripts directly, skipping this tutorial.\n\n\n\n\nConnecting to the simulator\n\n\nThe steps to connect to the simulator \nderives from CARLA\n. A client object is created from which the world is received:\n\n\nclient = carla.Client('localhost', 2000)\nworld = client.get_world()\n\n\n\n\nRoads and roadmarks\n\n\nRoads are represented using SUMO networks, which are loaded into memory via a SUMO network file:\n\n\nsumo_network = carla.SumoNetwork.load(PATH_TO_SUMO_NETWORK_FILE)\n\n\n\n\nThe occupancy map (i.e. mesh) for the road can be produced by calling:\n\n\nsumo_network_occupancy = sumo_network.create_occupancy_map()\n\n\n\n\nIf you required roadmarks (e.g. lane dividers), SUMMIT provides a fully automated way to generate the roadmarks' mesh:\n\n\nroadmark_occupancy = sumo_network.create_roadmark_occupancy_map()\n\n\n\n\nThe road and roadmarks' meshes are then sent to the simulator and spawned dynamically:\n\n\n# Get mesh triangles, and defines material and segmentation tag for road.\n# Roadmarks' mesh is subtracted from the road's mesh to prevent flickering due to overlaps.\nroad_triangles = sumo_network_occupancy.difference(roadmark_occupancy).get_mesh_triangles()\nroad_material = '/Game/Carla/Static/GenericMaterials/Masters/LowComplexity/M_Road1'\nroad_segmentation = 7 # Road (defined by CARLA).\n\n# Get mesh triangles, and defines material and segmentation tag for roadmarks.\nroadmark_triangles = roadmark_occupancy.get_mesh_triangles()\nroadmark_material = '/Game/Carla/Static/GenericMaterials/LaneMarking/M_MarkingLane_W'\nroadmark_segmentation = 6 # Road line (defined by CARLA).\n\n# Spawn road and roadmarks dynamically in simulator.\nworld.spawn_dynamic_mesh(road_triangles, road_material, road_segmentation)\nworld.spawn_dynamic_mesh(roadmark_triangles, roadmark_material, roadmark_segmentation)\n\n\n\n\nSidewalks\n\n\nSidewalks are represented using a set of oriented polygons with holes using \ncarla.Sidewalk\n objects. \nIn SUMMIT, sidewalks are automatically calculated as boundaries along road meshes:\n\n\n# Create sidewalk 1.5 meters from road's mesh.\nsidewalk = sumo_network_occupancy.create_sidewalk(1.5)\n\n# Create sidewalk's mesh for a sidewalk width of 3.0 meters.\nsidewalk_occupancy = sidewalk.create_occupancy_map(3.0)\n\n# Get mesh triangles, and defines sidewalk material and segmentation tag for sidewalk.\nsidewalk_triangles = sidewalk_occupancy.get_mesh_triangles()\nsidewalk_material = '/Game/Carla/Static/GenericMaterials/Ground/GroundWheatField_Mat'\nsidewalk_segmentation = 8 # Sidewalk (defined by CARLA).\n\n# Spawn sidewalk dynamically in simulator.\nworld.spawn_dynamic_mesh(sidewalk_triangles, sidewalk_material, sidewalk_segmentation)\n\n\n\n\nLandmarks\n\n\nLandmarks can be loaded from the map's OSM file:\n\n\nlandmark_occupancies = carla.Landmark.load(PATH_TO_OSM_FILE, sumo_network.offset)\n\n\n\n\n\n\nNote\n\n\nThe \nsumo_network.offset\n argument applies an offset to each landmark equal to the offset applied to the SUMO network. This is required because the SUMO network itself is offset (by \nsumo_network.offset\n) such that its bounds are aligned to the origin in the simulator. On the other hand, the landmarks maintain their global geographic position. Without applying the correct offset, the landmarks may end up at positions far away from the SUMO network.\n\n\n\n\nFor each landmark, we can retrieve the ground, ceiling, and wall meshes to be spawned in the simulator:\n\n\nlandmark_material = '/Game/Carla/Static/Buildings/aa_wall_mat'\nlandmark_segmentation = 1 # Building (defined by CARLA)\n\nfor landmark_occupancy in landmark_occupancies:\n    # Get ground mesh, applying a vertical offset of 0 meters.\n    ground_mesh_triangles = landmark_occupancy.get_mesh_triangles(0.0)\n\n    # Get ceiling mesh triangles, with a vertical offset of 20.0 meters.\n    ceiling_mesh_triangles = landmark_occupancy.get_mesh_triangles(20.0)\n\n    # Get vertically rising mesh triangles, with a height of 20.0 meters.\n    wall_mesh_triangles = landmark_occupancy.get_wall_mesh_triangles(20.0)\n\n    # Spawn meshes dynamically in simulator.\n    world.spawn_dynamic_mesh(ground_mesh_triangles, landmark_material, landmark_segmentation)\n    world.spawn_dynamic_mesh(ceiling_mesh_triangles, landmark_material, landmark_segmentation)\n    world.spawn_dynamic_mesh(wall_mesh_triangles, landmark_material, landmark_segmentation)\n\n\n\n\nThe landmarks may sometime overlap with the roads and sidewalks. You may wish to do some preprocessing to remove these overlaps:\n\n\nsumo_network_occupancy = ... # Get road mesh.\nsidewalk_occupancy = ... # Get sidewalk mesh.\nlandmark_occupancies = ... # Get landmark meshes.\n\n# Subtract road mesh and sidewalk mesh from landmark meshes.\nlandmark_occupancies = [\n        l.difference(sumo_network_occupancy).difference(sidewalk_occupancy) \n        for l in landmark_occupancies]\n\n# Filter empty landmark meshes.\nlandmark_occupancies = [l for l in landmark_occupancies if not l.is_empty]\n\n\n\n\nSatellite/general imagery\n\n\nTo spawn satellite imagery in SUMMIT, we provide a utility script at \n<summit_root>/PythonAPI/examples/spawn_imagery.py\n. It assumes that you have already \ndownloadeded the satellite imagery\n. To use, run\n\n\nspawn_imagery.py --dataset <map_name>\n\n\n\n\n\n\nNote\n\n\nSpawning satellite imagery involves a tedious amount of work (such as looking up the map tile indices from geographical coordinates), and we highly recommend using the provided script which already deals with these efforts.\n\n\n\n\nThe dynamic image tiles that SUMMIT expose to spawn satellite imagery can also be used to spawn any JPEG image in general. The below example spawns a an arbitrary image on a square region that is slanted along the z axis.\n\n\nwith open(JPEG_PATH, 'rb') as f:\n    # NOTE: Python 2 reads the file as a string instead of as an\n    # array of bytes. ord(b) checks for this and converts accordingly.\n    data = [ord(b) if isinstance(b, str) else b for b in f.read()]\n\nsegmentation = 9 # Vegetation (defined by CARLA)\nbounds_min = carla.Vector3D(0, 0, -10)\nbounds_max = carla.Vector3D(100, 100, 10)\n\nworld.spawn_dynamic_tile_mesh(bounds_min, bounds_max, data, segmentation)\n\n\n\n\nSaving and loading meshes\n\n\nYou may wish to save meshes onto the disk, and reload them for future use, speeding up loading times by elimiating the unnecessary recomputations:\n\n\n# Saves mesh to the disk at SAVE_PATH.\nsumo_network_occupancy.save(SAVE_PATH)\n\n# Reload mesh from the disk.\nsumo_network_occupancy = carla.OccupancyMap.load(SAVE_PATH)\n\n# Spawn dynamically in simulator.\nworld.spawn_dynamic_mesh(sumo_network_occupancy.get_mesh_triangles(), road_material, road_segmentation)\n\n\n\n\nThis example works for any \ncarla.OccupancyMap\n instance, not just for roads.",
            "title": "Loading and spawning maps"
        },
        {
            "location": "/tutorials/loading_and_spawning_maps/#connecting-to-the-simulator",
            "text": "The steps to connect to the simulator  derives from CARLA . A client object is created from which the world is received:  client = carla.Client('localhost', 2000)\nworld = client.get_world()",
            "title": "Connecting to the simulator"
        },
        {
            "location": "/tutorials/loading_and_spawning_maps/#roads-and-roadmarks",
            "text": "Roads are represented using SUMO networks, which are loaded into memory via a SUMO network file:  sumo_network = carla.SumoNetwork.load(PATH_TO_SUMO_NETWORK_FILE)  The occupancy map (i.e. mesh) for the road can be produced by calling:  sumo_network_occupancy = sumo_network.create_occupancy_map()  If you required roadmarks (e.g. lane dividers), SUMMIT provides a fully automated way to generate the roadmarks' mesh:  roadmark_occupancy = sumo_network.create_roadmark_occupancy_map()  The road and roadmarks' meshes are then sent to the simulator and spawned dynamically:  # Get mesh triangles, and defines material and segmentation tag for road.\n# Roadmarks' mesh is subtracted from the road's mesh to prevent flickering due to overlaps.\nroad_triangles = sumo_network_occupancy.difference(roadmark_occupancy).get_mesh_triangles()\nroad_material = '/Game/Carla/Static/GenericMaterials/Masters/LowComplexity/M_Road1'\nroad_segmentation = 7 # Road (defined by CARLA).\n\n# Get mesh triangles, and defines material and segmentation tag for roadmarks.\nroadmark_triangles = roadmark_occupancy.get_mesh_triangles()\nroadmark_material = '/Game/Carla/Static/GenericMaterials/LaneMarking/M_MarkingLane_W'\nroadmark_segmentation = 6 # Road line (defined by CARLA).\n\n# Spawn road and roadmarks dynamically in simulator.\nworld.spawn_dynamic_mesh(road_triangles, road_material, road_segmentation)\nworld.spawn_dynamic_mesh(roadmark_triangles, roadmark_material, roadmark_segmentation)",
            "title": "Roads and roadmarks"
        },
        {
            "location": "/tutorials/loading_and_spawning_maps/#sidewalks",
            "text": "Sidewalks are represented using a set of oriented polygons with holes using  carla.Sidewalk  objects. \nIn SUMMIT, sidewalks are automatically calculated as boundaries along road meshes:  # Create sidewalk 1.5 meters from road's mesh.\nsidewalk = sumo_network_occupancy.create_sidewalk(1.5)\n\n# Create sidewalk's mesh for a sidewalk width of 3.0 meters.\nsidewalk_occupancy = sidewalk.create_occupancy_map(3.0)\n\n# Get mesh triangles, and defines sidewalk material and segmentation tag for sidewalk.\nsidewalk_triangles = sidewalk_occupancy.get_mesh_triangles()\nsidewalk_material = '/Game/Carla/Static/GenericMaterials/Ground/GroundWheatField_Mat'\nsidewalk_segmentation = 8 # Sidewalk (defined by CARLA).\n\n# Spawn sidewalk dynamically in simulator.\nworld.spawn_dynamic_mesh(sidewalk_triangles, sidewalk_material, sidewalk_segmentation)",
            "title": "Sidewalks"
        },
        {
            "location": "/tutorials/loading_and_spawning_maps/#landmarks",
            "text": "Landmarks can be loaded from the map's OSM file:  landmark_occupancies = carla.Landmark.load(PATH_TO_OSM_FILE, sumo_network.offset)   Note  The  sumo_network.offset  argument applies an offset to each landmark equal to the offset applied to the SUMO network. This is required because the SUMO network itself is offset (by  sumo_network.offset ) such that its bounds are aligned to the origin in the simulator. On the other hand, the landmarks maintain their global geographic position. Without applying the correct offset, the landmarks may end up at positions far away from the SUMO network.   For each landmark, we can retrieve the ground, ceiling, and wall meshes to be spawned in the simulator:  landmark_material = '/Game/Carla/Static/Buildings/aa_wall_mat'\nlandmark_segmentation = 1 # Building (defined by CARLA)\n\nfor landmark_occupancy in landmark_occupancies:\n    # Get ground mesh, applying a vertical offset of 0 meters.\n    ground_mesh_triangles = landmark_occupancy.get_mesh_triangles(0.0)\n\n    # Get ceiling mesh triangles, with a vertical offset of 20.0 meters.\n    ceiling_mesh_triangles = landmark_occupancy.get_mesh_triangles(20.0)\n\n    # Get vertically rising mesh triangles, with a height of 20.0 meters.\n    wall_mesh_triangles = landmark_occupancy.get_wall_mesh_triangles(20.0)\n\n    # Spawn meshes dynamically in simulator.\n    world.spawn_dynamic_mesh(ground_mesh_triangles, landmark_material, landmark_segmentation)\n    world.spawn_dynamic_mesh(ceiling_mesh_triangles, landmark_material, landmark_segmentation)\n    world.spawn_dynamic_mesh(wall_mesh_triangles, landmark_material, landmark_segmentation)  The landmarks may sometime overlap with the roads and sidewalks. You may wish to do some preprocessing to remove these overlaps:  sumo_network_occupancy = ... # Get road mesh.\nsidewalk_occupancy = ... # Get sidewalk mesh.\nlandmark_occupancies = ... # Get landmark meshes.\n\n# Subtract road mesh and sidewalk mesh from landmark meshes.\nlandmark_occupancies = [\n        l.difference(sumo_network_occupancy).difference(sidewalk_occupancy) \n        for l in landmark_occupancies]\n\n# Filter empty landmark meshes.\nlandmark_occupancies = [l for l in landmark_occupancies if not l.is_empty]",
            "title": "Landmarks"
        },
        {
            "location": "/tutorials/loading_and_spawning_maps/#satellitegeneral-imagery",
            "text": "To spawn satellite imagery in SUMMIT, we provide a utility script at  <summit_root>/PythonAPI/examples/spawn_imagery.py . It assumes that you have already  downloadeded the satellite imagery . To use, run  spawn_imagery.py --dataset <map_name>   Note  Spawning satellite imagery involves a tedious amount of work (such as looking up the map tile indices from geographical coordinates), and we highly recommend using the provided script which already deals with these efforts.   The dynamic image tiles that SUMMIT expose to spawn satellite imagery can also be used to spawn any JPEG image in general. The below example spawns a an arbitrary image on a square region that is slanted along the z axis.  with open(JPEG_PATH, 'rb') as f:\n    # NOTE: Python 2 reads the file as a string instead of as an\n    # array of bytes. ord(b) checks for this and converts accordingly.\n    data = [ord(b) if isinstance(b, str) else b for b in f.read()]\n\nsegmentation = 9 # Vegetation (defined by CARLA)\nbounds_min = carla.Vector3D(0, 0, -10)\nbounds_max = carla.Vector3D(100, 100, 10)\n\nworld.spawn_dynamic_tile_mesh(bounds_min, bounds_max, data, segmentation)",
            "title": "Satellite/general imagery"
        },
        {
            "location": "/tutorials/loading_and_spawning_maps/#saving-and-loading-meshes",
            "text": "You may wish to save meshes onto the disk, and reload them for future use, speeding up loading times by elimiating the unnecessary recomputations:  # Saves mesh to the disk at SAVE_PATH.\nsumo_network_occupancy.save(SAVE_PATH)\n\n# Reload mesh from the disk.\nsumo_network_occupancy = carla.OccupancyMap.load(SAVE_PATH)\n\n# Spawn dynamically in simulator.\nworld.spawn_dynamic_mesh(sumo_network_occupancy.get_mesh_triangles(), road_material, road_segmentation)  This example works for any  carla.OccupancyMap  instance, not just for roads.",
            "title": "Saving and loading meshes"
        },
        {
            "location": "/tutorials/using_roads_and_sidewalks/",
            "text": "Using Roads and Sidewalks\n\n\n\nSpawning on roads\n\n\nOn roads, route points, stored as \ncarla.SumoNetworkRoutePoint\n objects, hold semantic information such the point's road, lane, and offset along lane. The SUMO network, stored as a \ncarla.SumoNetwork\n, is used to traverse these route points spatially and topologically.\n\n\nOne way to spawn points is to first lookup the route point on the road nearest to an arbitrary position.\n\n\n# Load SUMO network.\nsumo_network = carla.SumoNetwork.load(PATH_TO_SUMO_NETWORK_FILE)\n\n# Get arbitrary position.\nposition = carla.Vector(100, 100)\n\n# Get nearest route point on SUMO network.\nroute_point = sumo_network.get_nearest_route_point(position)\n\n\n\n\nSince the route point holds only semantic information and not the actual position, a translational query is required to determine the actual position to spawn the agent:\n\n\n# Get route point position.\nroute_point_position = sumo_network.get_route_point_position(route_point)\n\n# Get route point transform\nroute_point_transform = carla.Transform()\nroute_point_transform.x = route_point_position.x\nroute_point_transform.y = route_point_position.y\nroute_point_transform.z = 0.5 # Spawn at a height of 0.5 meters.\n\n# Spawn actor. See CARLA's documentation.\nworld.spawn_actor(BLUEPRINT, route_point_transform)\n\n\n\n\nAlternatively, you can use the \ncarla.SegmentMap\n class to generate route points uniformly distributed along the lanes of the road. The \ncarla.SegmentMap\n class is a data structure to work with line segments, optimized for uniform sampling of points over stored line segments. \n\n\n# Get segments of SUMO network.\nsumo_network_segments = sumo_network.create_segment_map()\n\n# Randmly pick spawn point. Note that this returns a position directly, not a route point.\nroute_point_position = sumo_network_segments.rand_point()\n\n\n\n\nIt is also possible to bound the spawn segments to a certain region, for example a rectangular bounding box:\n\n\n# Get segments of SUMO network.\nsumo_network_segments = sumo_network.create_segment_map()\n\n# Define bounding box.\nbounds_min = carla.Vector2D(-50, -50)\nbounds_max = carla.Vector2D(100, 300)\nbounds_occupancy = carla.OccupancyMap(bounds_min, bounds_max)\n\n# Calculate intersection of line segments with bounding box.\nspawn_segments = sumo_network_segments.intersection(bounds_occupancy)\n\n\n\n\n\n\nNote\n\n\nIn SUMMIT, we strive to a support a wide range of geometric manipulations. As such, you can go all funky and do stuff like:\n\n\n# Arbitrary polygon.\npolygon = carla.OccupancyMap([carla.Vector2D(-50, -50),\n    carla.Vector2D(-50, 100), carla.Vector2D(30, 200),\n    carla.Vector2D(70, 70), carla.Vector2D(100, -70)])\n# Arbitrary rectangle.\nrectangle1 = carla.OccupancyMap(carla.Vector2D(-30, -30), carla.Vector2D(200, 300))\n# Another arbitrary rectangle.\nrectangle2 = carla.OccupancyMap(carla.Vector2D(-70, 30), carla.Vector2D(100, 200))\n# Some combination of areas.\nspawn_occupancy = polygon.union(rectangle1).difference(rectangle2)\n# Crop line segments.\nspawn_segments = sumo_network_segments.intersection(spawn_occupancy)\n\n\n\n\n\nNavigation on roads\n\n\nOn roads, the SUMO network can be used to traverse the route points spatially and topologically.\n\n\nThe below example fetches the nearest route point given the agent's current position, and randomly selects from topologically possible next route points a set distance ahead.\n\n\n# Get 2D position of actor.\nlocation = actor.get_location()\nposition2d = carla.Vector2D(location.x, location.y)\n\n# Lookup nearest route point.\nroute_point = sumo_network.get_nearest_route_point(position2d)\n\n# Get all route points 1 meter ahead.\nnext_route_points = sumo_network.get_next_route_points(route_point, 1.0)\n\n# Randomly select next route point.\nnext_route_point = random.choice(next_route_points)\n\n\n\n\nSince the route point only holds semantic information and not the actual position, a translational query is required to determine the actual position:\n\n\n# Get next route point's position.\nposition = sumo_network.get_route_point_position(next_route_point)\n\n\n\n\nwhich can then be used for required tasks, such as for feedback to some steering controller for vehicles.\n\n\nSpawning on sidewalks\n\n\nOn sidewalks, things work very similar to roads. Sidewalks also have route points, stored as \ncarla.SidewalkRoutePoint\n objects, which hold semantic information such as the point's polygon, segment, and offset along segment.  The sidewalk, stored as a \ncarla.Sidewalk\n, is used to traverse these route points spatially and topologically.\n\n\nOne way to spawn points is to first lookup the route point on the road nearest to an arbitrary position.\n\n\n# Load SUMO network.\nsumo_network = carla.SumoNetwork.load(PATH_TO_SUMO_NETWORK_FILE)\n\n# Calculate sidewalk 1.5 meters from road's mesh.\nsumo_network_occupancy = sumo_network.create_occupancy_map()\nsidewalk = sumo_network_occupancy.create_sidewalk(1.5)\n\n# Get arbitrary position.\nposition = carla.Vector(100, 100)\n\n# Get nearest route point on sidewalk.\nroute_point = sidewalk.get_nearest_route_point(position)\n\n\n\n\nSince the route point holds only semantic information and not the actual position, a translational query is required to determine the actual position to spawn the agent:\n\n\n# Get route point position.\nroute_point_position = sidewalk.get_route_point_position(route_point)\n\n# Get route point transform\nroute_point_transform = carla.Transform()\nroute_point_transform.x = route_point_position.x\nroute_point_transform.y = route_point_position.y\nroute_point_transform.z = 0.5 # Spawn at a height of 0.5 meters.\n\n# Spawn actor. See CARLA's documentation.\nworld.spawn_actor(BLUEPRINT, route_point_transform)\n\n\n\n\nAlternatively, you can use the \ncarla.SegmentMap\n class to generate route points uniformly distributed along the paths of the sidewalk. The \ncarla.SegmentMap\n class is a data structure to work with line segments, optimized for uniform sampling of points over stored line segments. \n\n\n# Get segments of sidewalk.\nsidewalk_segments = sidewalk.create_segment_map()\n\n# Randmly pick spawn point. Note that this returns a position directly, not a route point.\nroute_point_position = sidewalk_segments.rand_point()\n\n\n\n\nIt is also possible to bound the spawn segments to a certain region, for example a rectangular bounding box:\n\n\n# Get segments of sidewalk.\nsidewalk_segments = sidewalk.create_segment_map()\n\n# Define bounding box.\nbounds_min = carla.Vector2D(-50, -50)\nbounds_max = carla.Vector2D(100, 300)\nbounds_occupancy = carla.OccupancyMap(bounds_min, bounds_max)\n\n# Calculate intersection of line segments with bounding box.\nspawn_segments = sidewalk_segments.intersection(bounds_occupancy)\n\n\n\n\n\n\nNote\n\n\nIn SUMMIT, we strive to a support a wide range of geometric manipulations. As such, you can go all funky and do stuff like:\n\n\n# Arbitrary polygon.\npolygon = carla.OccupancyMap([carla.Vector2D(-50, -50),\n    carla.Vector2D(-50, 100), carla.Vector2D(30, 200),\n    carla.Vector2D(70, 70), carla.Vector2D(100, -70)])\n# Arbitrary rectangle.\nrectangle1 = carla.OccupancyMap(carla.Vector2D(-30, -30), carla.Vector2D(200, 300))\n# Another arbitrary rectangle.\nrectangle2 = carla.OccupancyMap(carla.Vector2D(-70, 30), carla.Vector2D(100, 200))\n# Some combination of areas.\nspawn_occupancy = polygon.union(rectangle1).difference(rectangle2)\n# Crop line segments.\nspawn_segments = sidewalk_segments.intersection(spawn_occupancy)\n\n\n\n\n\nNavigating sidewalks\n\n\nOn sidewalks, the sidewalk can be used to traverse the route points spatially and topologically.\n\n\nThe below example fetches the nearest route point given the agent's current position, and selects the next route point a set distance anticlockwise along the route point's polygon. \n\n\n\n\nNote\n\n\nSidewalks are structured using closed polygons, so there will always be exactly one next route point. Additionally, sidewalks in SUMMIT are always oriented anticlockwise, so that the next route point always goes anticlockwise along the current route point's polygon. \n\n\n\n\n# Get 2D position of actor.\nlocation = actor.get_location()\nposition2d = carla.Vector2D(location.x, location.y)\n\n# Lookup nearest route point.\nroute_point = sidewalk.get_nearest_route_point(position2d)\n\n# Get route point 1 meter anticlockwise along route point's polygon.\nnext_route_point = sidewalk.get_next_route_point(route_point, 1.0)\n\n\n\n\nTo get the next route point clockwise (instead of anticlockwise) along the current route point's polygon, use the \nget_previous_route_point\n method instead:\n\n\n# Get route point 1 meter clockwise along route point's polygon.\nnext_route_point = sidewalk.get_previous_route_point(route_point, 1.0)\n\n\n\n\nYou can also fetch the nearest point on an adjacent sidewalk polygon (i.e. on the other side of the road):\n\n\n# Get nearest adjacent route point, at most 50 meters away.\n# If such a route point exists, this returns None. a list of exactly one item.\nnext_route_point = sidewalk.get_adjacent_route_point(route_point, 50.0)\n\n\n\n\nSince the route point only holds semantic information and not the actual position, a translational query is required to determine the actual position:\n\n\n# Get next route point's position.\nposition = sidewalk.get_route_point_position(next_route_point)\n\n\n\n\nwhich can then be used for required tasks, such as for feedback to some heading controller for pedestrians.",
            "title": "Using roads and sidewalks"
        },
        {
            "location": "/tutorials/using_roads_and_sidewalks/#spawning-on-roads",
            "text": "On roads, route points, stored as  carla.SumoNetworkRoutePoint  objects, hold semantic information such the point's road, lane, and offset along lane. The SUMO network, stored as a  carla.SumoNetwork , is used to traverse these route points spatially and topologically.  One way to spawn points is to first lookup the route point on the road nearest to an arbitrary position.  # Load SUMO network.\nsumo_network = carla.SumoNetwork.load(PATH_TO_SUMO_NETWORK_FILE)\n\n# Get arbitrary position.\nposition = carla.Vector(100, 100)\n\n# Get nearest route point on SUMO network.\nroute_point = sumo_network.get_nearest_route_point(position)  Since the route point holds only semantic information and not the actual position, a translational query is required to determine the actual position to spawn the agent:  # Get route point position.\nroute_point_position = sumo_network.get_route_point_position(route_point)\n\n# Get route point transform\nroute_point_transform = carla.Transform()\nroute_point_transform.x = route_point_position.x\nroute_point_transform.y = route_point_position.y\nroute_point_transform.z = 0.5 # Spawn at a height of 0.5 meters.\n\n# Spawn actor. See CARLA's documentation.\nworld.spawn_actor(BLUEPRINT, route_point_transform)  Alternatively, you can use the  carla.SegmentMap  class to generate route points uniformly distributed along the lanes of the road. The  carla.SegmentMap  class is a data structure to work with line segments, optimized for uniform sampling of points over stored line segments.   # Get segments of SUMO network.\nsumo_network_segments = sumo_network.create_segment_map()\n\n# Randmly pick spawn point. Note that this returns a position directly, not a route point.\nroute_point_position = sumo_network_segments.rand_point()  It is also possible to bound the spawn segments to a certain region, for example a rectangular bounding box:  # Get segments of SUMO network.\nsumo_network_segments = sumo_network.create_segment_map()\n\n# Define bounding box.\nbounds_min = carla.Vector2D(-50, -50)\nbounds_max = carla.Vector2D(100, 300)\nbounds_occupancy = carla.OccupancyMap(bounds_min, bounds_max)\n\n# Calculate intersection of line segments with bounding box.\nspawn_segments = sumo_network_segments.intersection(bounds_occupancy)   Note  In SUMMIT, we strive to a support a wide range of geometric manipulations. As such, you can go all funky and do stuff like:  # Arbitrary polygon.\npolygon = carla.OccupancyMap([carla.Vector2D(-50, -50),\n    carla.Vector2D(-50, 100), carla.Vector2D(30, 200),\n    carla.Vector2D(70, 70), carla.Vector2D(100, -70)])\n# Arbitrary rectangle.\nrectangle1 = carla.OccupancyMap(carla.Vector2D(-30, -30), carla.Vector2D(200, 300))\n# Another arbitrary rectangle.\nrectangle2 = carla.OccupancyMap(carla.Vector2D(-70, 30), carla.Vector2D(100, 200))\n# Some combination of areas.\nspawn_occupancy = polygon.union(rectangle1).difference(rectangle2)\n# Crop line segments.\nspawn_segments = sumo_network_segments.intersection(spawn_occupancy)",
            "title": "Spawning on roads"
        },
        {
            "location": "/tutorials/using_roads_and_sidewalks/#navigation-on-roads",
            "text": "On roads, the SUMO network can be used to traverse the route points spatially and topologically.  The below example fetches the nearest route point given the agent's current position, and randomly selects from topologically possible next route points a set distance ahead.  # Get 2D position of actor.\nlocation = actor.get_location()\nposition2d = carla.Vector2D(location.x, location.y)\n\n# Lookup nearest route point.\nroute_point = sumo_network.get_nearest_route_point(position2d)\n\n# Get all route points 1 meter ahead.\nnext_route_points = sumo_network.get_next_route_points(route_point, 1.0)\n\n# Randomly select next route point.\nnext_route_point = random.choice(next_route_points)  Since the route point only holds semantic information and not the actual position, a translational query is required to determine the actual position:  # Get next route point's position.\nposition = sumo_network.get_route_point_position(next_route_point)  which can then be used for required tasks, such as for feedback to some steering controller for vehicles.",
            "title": "Navigation on roads"
        },
        {
            "location": "/tutorials/using_roads_and_sidewalks/#spawning-on-sidewalks",
            "text": "On sidewalks, things work very similar to roads. Sidewalks also have route points, stored as  carla.SidewalkRoutePoint  objects, which hold semantic information such as the point's polygon, segment, and offset along segment.  The sidewalk, stored as a  carla.Sidewalk , is used to traverse these route points spatially and topologically.  One way to spawn points is to first lookup the route point on the road nearest to an arbitrary position.  # Load SUMO network.\nsumo_network = carla.SumoNetwork.load(PATH_TO_SUMO_NETWORK_FILE)\n\n# Calculate sidewalk 1.5 meters from road's mesh.\nsumo_network_occupancy = sumo_network.create_occupancy_map()\nsidewalk = sumo_network_occupancy.create_sidewalk(1.5)\n\n# Get arbitrary position.\nposition = carla.Vector(100, 100)\n\n# Get nearest route point on sidewalk.\nroute_point = sidewalk.get_nearest_route_point(position)  Since the route point holds only semantic information and not the actual position, a translational query is required to determine the actual position to spawn the agent:  # Get route point position.\nroute_point_position = sidewalk.get_route_point_position(route_point)\n\n# Get route point transform\nroute_point_transform = carla.Transform()\nroute_point_transform.x = route_point_position.x\nroute_point_transform.y = route_point_position.y\nroute_point_transform.z = 0.5 # Spawn at a height of 0.5 meters.\n\n# Spawn actor. See CARLA's documentation.\nworld.spawn_actor(BLUEPRINT, route_point_transform)  Alternatively, you can use the  carla.SegmentMap  class to generate route points uniformly distributed along the paths of the sidewalk. The  carla.SegmentMap  class is a data structure to work with line segments, optimized for uniform sampling of points over stored line segments.   # Get segments of sidewalk.\nsidewalk_segments = sidewalk.create_segment_map()\n\n# Randmly pick spawn point. Note that this returns a position directly, not a route point.\nroute_point_position = sidewalk_segments.rand_point()  It is also possible to bound the spawn segments to a certain region, for example a rectangular bounding box:  # Get segments of sidewalk.\nsidewalk_segments = sidewalk.create_segment_map()\n\n# Define bounding box.\nbounds_min = carla.Vector2D(-50, -50)\nbounds_max = carla.Vector2D(100, 300)\nbounds_occupancy = carla.OccupancyMap(bounds_min, bounds_max)\n\n# Calculate intersection of line segments with bounding box.\nspawn_segments = sidewalk_segments.intersection(bounds_occupancy)   Note  In SUMMIT, we strive to a support a wide range of geometric manipulations. As such, you can go all funky and do stuff like:  # Arbitrary polygon.\npolygon = carla.OccupancyMap([carla.Vector2D(-50, -50),\n    carla.Vector2D(-50, 100), carla.Vector2D(30, 200),\n    carla.Vector2D(70, 70), carla.Vector2D(100, -70)])\n# Arbitrary rectangle.\nrectangle1 = carla.OccupancyMap(carla.Vector2D(-30, -30), carla.Vector2D(200, 300))\n# Another arbitrary rectangle.\nrectangle2 = carla.OccupancyMap(carla.Vector2D(-70, 30), carla.Vector2D(100, 200))\n# Some combination of areas.\nspawn_occupancy = polygon.union(rectangle1).difference(rectangle2)\n# Crop line segments.\nspawn_segments = sidewalk_segments.intersection(spawn_occupancy)",
            "title": "Spawning on sidewalks"
        },
        {
            "location": "/tutorials/using_roads_and_sidewalks/#navigating-sidewalks",
            "text": "On sidewalks, the sidewalk can be used to traverse the route points spatially and topologically.  The below example fetches the nearest route point given the agent's current position, and selects the next route point a set distance anticlockwise along the route point's polygon.    Note  Sidewalks are structured using closed polygons, so there will always be exactly one next route point. Additionally, sidewalks in SUMMIT are always oriented anticlockwise, so that the next route point always goes anticlockwise along the current route point's polygon.    # Get 2D position of actor.\nlocation = actor.get_location()\nposition2d = carla.Vector2D(location.x, location.y)\n\n# Lookup nearest route point.\nroute_point = sidewalk.get_nearest_route_point(position2d)\n\n# Get route point 1 meter anticlockwise along route point's polygon.\nnext_route_point = sidewalk.get_next_route_point(route_point, 1.0)  To get the next route point clockwise (instead of anticlockwise) along the current route point's polygon, use the  get_previous_route_point  method instead:  # Get route point 1 meter clockwise along route point's polygon.\nnext_route_point = sidewalk.get_previous_route_point(route_point, 1.0)  You can also fetch the nearest point on an adjacent sidewalk polygon (i.e. on the other side of the road):  # Get nearest adjacent route point, at most 50 meters away.\n# If such a route point exists, this returns None. a list of exactly one item.\nnext_route_point = sidewalk.get_adjacent_route_point(route_point, 50.0)  Since the route point only holds semantic information and not the actual position, a translational query is required to determine the actual position:  # Get next route point's position.\nposition = sidewalk.get_route_point_position(next_route_point)  which can then be used for required tasks, such as for feedback to some heading controller for pedestrians.",
            "title": "Navigating sidewalks"
        },
        {
            "location": "/tutorials/preparing_maps/",
            "text": "Preparing Maps\n\n\n\n\n\nImportant\n\n\nSUMMIT comes with a \nset of maps ready for use\n. The steps in this page have already been done for the built-in maps. This page is required only if you wish to use your own additional maps.\n\n\n\n\nMap data sources\n\n\nFor a given map, SUMMIT requires both a corresponding OSM file and SUMO network, which provide the respective information:\n\n\n\n\nOSM file: Landmark data for spawning landmark objects.\n\n\nSUMO network: Road contexts, and geographical bounds for satellite imagery.\n\n\n\n\nNote that sidewalk information is not required at all, since SUMMIT automatically calculates the sidewalks as boundaries along roads.\n\n\n\n\nNote\n\n\nWhen working with real-world maps, the SUMO networks are typically generated from the OSM file. It is thus common that both the OSM file and SUMO network contains the same road information. The road information in the OSM file is simply unused after producing the SUMO network.\n\n\nWhile it is possible to use the road information in the OSM file directly, we choose to use a SUMO network as it provides a much more detailed representation to work with. In addition, SUMO comes with a flexible suite of tools to aid making fine adjustments to the SUMO networks.\n\n\n\n\n\n\nImportant\n\n\nSUMMIT uses the convention of storing all map data inside the \n<summit-root>/Data/\n folder. All data files pertaining to the same map should be given the same name with different extensions (e.g. \nmeskel_square.osm\n, \nmeskel_square.net.xml\n). In addition, underscores should be in the file name to separate words in the map name.\n\n\n\n\nObtaining OSM files\n\n\nTo obtain high-quality real-world OSM files, we recommend using \nOpenStreetMap's database\n. Simply zoom into the are of interest, and export the map to \n<summit_root>/Data/<map_name>.osm\n, giving your map a reasonable name.\n\n\nYou may wish to preprocess the OSM files using \nJOSM\n to remove road information unwanted from the simulation, such as service roads and footbridges.\n\n\n\n\nNote\n\n\nIn SUMMIT, we do not impose any restrictions on the source of OSM files. You are free to use any OSM file, even those produced by yourself.\n\n\n\n\nObtaining SUMO networks\n\n\nA SUMO network can be automatically obtained from an OSM file by using SUMO's \nNETCONVERT utility\n. This assumes that you have already setup the SUMO tools, as recommended in the \nrequirements section\n. The SUMO network should then be stored at \n<summit_root>/Data/<map_name>.net.xml\n, where \n<map_name>\n follows from that of the OSM file.\n\n\nWe provide an example script at \n<summit_root>/Scripts/osm2sumo.sh\n to convert an OSM file into a SUMO network. \n\n\nYou are recommended to postprocess the SUMO network using \nSUMO's NETEDIT\n after the conversion. The conversion process is not perfect, and we highly recommend postprocessing the SUMO network to eliminate any ambiguities.\n\n\n\n\nImportant\n\n\nSimilar to the OSM files, you are free to use any source of SUMO networks, including those produce by yourself. There are some restrictions however:\n\n\n\n\nAll lanes in SUMMIT are assumed to have a fixed width of 4.0 meters.\n\n\nBounds for OSM file and corresponding SUMO network must line up, if not landmarks may spawn incorrectly.\n\n\n\n\n\n\n\n\nNote\n\n\nFor SUMMIT's built in maps, we have done some postprocessing after the conversion, so it will be different from what is produced by simply calling the script.\n\n\n\n\nSpecifying simulation bounds\n\n\nFor a given map, SUMMIT's traffic simulation script simulates traffic in a user defined bounds, specified in \n<summit_root>/Data/<map_name>.sim_bounds\n. In order to use SUMMIT's built in traffic simulation script, a suitable bounds must be specified, so that the traffic simulation script knows where to bound the traffic.\n\n\nBounds in a \n.sim_bounds\n file are specified with the \nmin_x,min_y\n on the first line, and \nmax_x,max_y\n on the second line. For example, in \n<summit_root>/Data/meskel_square.sim_bounds\n:\n\n\n350,300\n550,500\n\n\n\nThese are in terms of CARLA coordinates. To find a suitable bounds for your map, you can use SUMO's NETEDIT tool as follows:\n\n\n\n\nOpen the map's SUMO network in SUMO's NETEDIT tool.\n\n\nFind a suitable rectangular bound and note down the corner coordinates given by NETEDIT. These are in SUMO coordinates.\n\n\nConvert each SUMO coordinates into CARLA coordinates by swapping the x and y values.\n\n\nTake the minimum and maximum of x and y among the converted CARLA coordinates.\n\n\n\n\nCaching map object meshes\n\n\nOften in SUMMIT, these mesh of map objects are calculated in order to spawn them dynamically in the simulator. The meshes can be calculated and saved beforehand to speed this process up.\n\n\nWe provide a utility script at \n<summit_root>/Scripts/extract_meshes.py\n that calculates the meshes of various map objects for a given map, assuming that both the OSM file and SUMO network have been prepared. The meshes are stored at \n<summit_root>/Data/\n with the respective names.\n\n\nAs an example, running the following:\n\n\nextract_meshes.py --dataset meskel_square\n\n\n\n\nuses \nmeskel_square.osm\n (OSM file) and \nmeskel_square.net.xml\n (SUMO network) to produce the following files in \n<summit_root>/Data/\n:\n\n\n\n\nmeskel_square.network.wkt\n: Road mesh.\n\n\nmeskel_square.roadmark.wkt\n: Roadmarks mesh.\n\n\nmeskel_square.sidewalk.wkt\n: Sidewalk mesh.\n\n\nmeskel_square.landmarks/*.landmark.wkt\n: Landmarks' meshes.\n\n\n\n\n(Optional) Downloading satellite imagery\n\n\nTo download satellite imagery for your map, ensure that you have your map's SUMO network located at \n<summit_root>/Data/<map_name>.net.xml\n, so that SUMMIT can locate the geographic bounds. Then, run the following utility script:\n\n\n<summit_root>/Scripts/download_imagery.py --dataset <map_name>\n\n\n\n\nThis downloads imagery that stored as tiles in \n<summit_root/Data/imagery/\n in \nSlippy Map format\n.",
            "title": "Preparing maps"
        },
        {
            "location": "/tutorials/preparing_maps/#map-data-sources",
            "text": "For a given map, SUMMIT requires both a corresponding OSM file and SUMO network, which provide the respective information:   OSM file: Landmark data for spawning landmark objects.  SUMO network: Road contexts, and geographical bounds for satellite imagery.   Note that sidewalk information is not required at all, since SUMMIT automatically calculates the sidewalks as boundaries along roads.   Note  When working with real-world maps, the SUMO networks are typically generated from the OSM file. It is thus common that both the OSM file and SUMO network contains the same road information. The road information in the OSM file is simply unused after producing the SUMO network.  While it is possible to use the road information in the OSM file directly, we choose to use a SUMO network as it provides a much more detailed representation to work with. In addition, SUMO comes with a flexible suite of tools to aid making fine adjustments to the SUMO networks.    Important  SUMMIT uses the convention of storing all map data inside the  <summit-root>/Data/  folder. All data files pertaining to the same map should be given the same name with different extensions (e.g.  meskel_square.osm ,  meskel_square.net.xml ). In addition, underscores should be in the file name to separate words in the map name.",
            "title": "Map data sources"
        },
        {
            "location": "/tutorials/preparing_maps/#obtaining-osm-files",
            "text": "To obtain high-quality real-world OSM files, we recommend using  OpenStreetMap's database . Simply zoom into the are of interest, and export the map to  <summit_root>/Data/<map_name>.osm , giving your map a reasonable name.  You may wish to preprocess the OSM files using  JOSM  to remove road information unwanted from the simulation, such as service roads and footbridges.   Note  In SUMMIT, we do not impose any restrictions on the source of OSM files. You are free to use any OSM file, even those produced by yourself.",
            "title": "Obtaining OSM files"
        },
        {
            "location": "/tutorials/preparing_maps/#obtaining-sumo-networks",
            "text": "A SUMO network can be automatically obtained from an OSM file by using SUMO's  NETCONVERT utility . This assumes that you have already setup the SUMO tools, as recommended in the  requirements section . The SUMO network should then be stored at  <summit_root>/Data/<map_name>.net.xml , where  <map_name>  follows from that of the OSM file.  We provide an example script at  <summit_root>/Scripts/osm2sumo.sh  to convert an OSM file into a SUMO network.   You are recommended to postprocess the SUMO network using  SUMO's NETEDIT  after the conversion. The conversion process is not perfect, and we highly recommend postprocessing the SUMO network to eliminate any ambiguities.   Important  Similar to the OSM files, you are free to use any source of SUMO networks, including those produce by yourself. There are some restrictions however:   All lanes in SUMMIT are assumed to have a fixed width of 4.0 meters.  Bounds for OSM file and corresponding SUMO network must line up, if not landmarks may spawn incorrectly.     Note  For SUMMIT's built in maps, we have done some postprocessing after the conversion, so it will be different from what is produced by simply calling the script.",
            "title": "Obtaining SUMO networks"
        },
        {
            "location": "/tutorials/preparing_maps/#specifying-simulation-bounds",
            "text": "For a given map, SUMMIT's traffic simulation script simulates traffic in a user defined bounds, specified in  <summit_root>/Data/<map_name>.sim_bounds . In order to use SUMMIT's built in traffic simulation script, a suitable bounds must be specified, so that the traffic simulation script knows where to bound the traffic.  Bounds in a  .sim_bounds  file are specified with the  min_x,min_y  on the first line, and  max_x,max_y  on the second line. For example, in  <summit_root>/Data/meskel_square.sim_bounds :  350,300\n550,500  These are in terms of CARLA coordinates. To find a suitable bounds for your map, you can use SUMO's NETEDIT tool as follows:   Open the map's SUMO network in SUMO's NETEDIT tool.  Find a suitable rectangular bound and note down the corner coordinates given by NETEDIT. These are in SUMO coordinates.  Convert each SUMO coordinates into CARLA coordinates by swapping the x and y values.  Take the minimum and maximum of x and y among the converted CARLA coordinates.",
            "title": "Specifying simulation bounds"
        },
        {
            "location": "/tutorials/preparing_maps/#caching-map-object-meshes",
            "text": "Often in SUMMIT, these mesh of map objects are calculated in order to spawn them dynamically in the simulator. The meshes can be calculated and saved beforehand to speed this process up.  We provide a utility script at  <summit_root>/Scripts/extract_meshes.py  that calculates the meshes of various map objects for a given map, assuming that both the OSM file and SUMO network have been prepared. The meshes are stored at  <summit_root>/Data/  with the respective names.  As an example, running the following:  extract_meshes.py --dataset meskel_square  uses  meskel_square.osm  (OSM file) and  meskel_square.net.xml  (SUMO network) to produce the following files in  <summit_root>/Data/ :   meskel_square.network.wkt : Road mesh.  meskel_square.roadmark.wkt : Roadmarks mesh.  meskel_square.sidewalk.wkt : Sidewalk mesh.  meskel_square.landmarks/*.landmark.wkt : Landmarks' meshes.",
            "title": "Caching map object meshes"
        },
        {
            "location": "/tutorials/preparing_maps/#optional-downloading-satellite-imagery",
            "text": "To download satellite imagery for your map, ensure that you have your map's SUMO network located at  <summit_root>/Data/<map_name>.net.xml , so that SUMMIT can locate the geographic bounds. Then, run the following utility script:  <summit_root>/Scripts/download_imagery.py --dataset <map_name>  This downloads imagery that stored as tiles in  <summit_root/Data/imagery/  in  Slippy Map format .",
            "title": "(Optional) Downloading satellite imagery"
        },
        {
            "location": "/tutorials/simulating_traffic/",
            "text": "Simulating Traffic\n\n\n\nSUMMIT comes with a built in script to simulate traffic on a map, located at \n<summit_root>/PythonAPI/examples/gamma_crowd.py\n. It makes use of the recent \nGAMMA\n prediction model to simulate heterogeneous agent behavior with sophisticated and unregulated behaviors.\n\n\nTo use the script, ensure that you have done the following:\n\n\n\n\nSpecified simulation bounds\n. This is required, since the script needs to know where to bound the agents. It only spawns agents within the specified bounds, and actively remove agents that go out of bounds. If are using a built-in map, the bounds have already been specified for you.\n\n\nSpawned the map objects that you need\n, such as roads and sidewalks.\n\n\n\n\nYou can then call \ngamma_crowd.py --dataset <map_name>\n to simulate the traffic. A list of all arguments are available with the \n--help\n flag, and it is recommended to read through the options as you may find them useful for your needs.",
            "title": "Simulating traffic"
        },
        {
            "location": "/tutorials/configure_the_simulation/",
            "text": "Configuring the Simulation\n\n\n\nChanging the crowd setting\n\n\nProperties of the simulated crowd can be controled via the arguments in \n<summit_root>/PythonAPI/examples/gamma_crowd.py\n. Important ones include:\n\n\n\n\n--num-car\n: the target number of car-like vehicles to be maitained in the scene.\n\n\n--num-bike\n: the target number of bikes and motorcycles to be maitained in the scene.\n\n\n--num-pedestrian\n: the target number of walkers to be maitained in the scene.\n\n\n--speed-car\n: the preferred speed of car-like vehicles. A uniform noise between [-0.5,0.5] will be added.\n\n\n--speed-bike\n: the preferred speed of bikes and motorcycles. A uniform noise between [-0.5,0.5] will be added.\n\n\n--speed-pedestrian\n: the preferred speed of walkers. A uniform noise between [-0.5,0.5] will be added.\n\n\n--clearance-car\n: clearance between other agents to be kept when spawning a vehicle.\n\n\n--clearance-bike\n: clearance between other agents to be kept when spawning a bike or motorcycle.\n\n\n--clearance-pedestrian\n: clearance between other agents to be kept when spawning a walker.\n\n\n--collision\n: enable or disable collision response for all traffic agents.\n\n\n\n\nChanging the Camera view\n\n\nThe camera view in SUMMIT can be either changed using mouse / keyboard, or through code.\n\n\nMouse / keyboard\n\n\nTo change the camera angle, hold down the right mouse button and drag your mouse around; \nTo change the camera position, hold down the right mouse button and use the WASD keys.\n\n\nPython API\n\n\nAlternatively, you can use the following code to change the view point in the server.\n\n\nclient = carla.Client(host, port)\nclient.get_world().get_spectator().set_transform(carla.Transform(                \n        carla.Location((x, y, z),\n        carla.Rotation(pitch, yaw, roll)))\n\n\n\n\nCamera actor\n\n\nIf you need to frequently change the view point of SUMMIT such as tracking an vehicle, we recommend to spawn a seperate camera actor and attach it to the tracked vehicle. An example script can be found in the \nexpert planner repo\n.",
            "title": "Configuring the simulation"
        },
        {
            "location": "/tutorials/configure_the_simulation/#changing-the-crowd-setting",
            "text": "Properties of the simulated crowd can be controled via the arguments in  <summit_root>/PythonAPI/examples/gamma_crowd.py . Important ones include:   --num-car : the target number of car-like vehicles to be maitained in the scene.  --num-bike : the target number of bikes and motorcycles to be maitained in the scene.  --num-pedestrian : the target number of walkers to be maitained in the scene.  --speed-car : the preferred speed of car-like vehicles. A uniform noise between [-0.5,0.5] will be added.  --speed-bike : the preferred speed of bikes and motorcycles. A uniform noise between [-0.5,0.5] will be added.  --speed-pedestrian : the preferred speed of walkers. A uniform noise between [-0.5,0.5] will be added.  --clearance-car : clearance between other agents to be kept when spawning a vehicle.  --clearance-bike : clearance between other agents to be kept when spawning a bike or motorcycle.  --clearance-pedestrian : clearance between other agents to be kept when spawning a walker.  --collision : enable or disable collision response for all traffic agents.",
            "title": "Changing the crowd setting"
        },
        {
            "location": "/tutorials/configure_the_simulation/#changing-the-camera-view",
            "text": "The camera view in SUMMIT can be either changed using mouse / keyboard, or through code.",
            "title": "Changing the Camera view"
        },
        {
            "location": "/tutorials/configure_the_simulation/#mouse-keyboard",
            "text": "To change the camera angle, hold down the right mouse button and drag your mouse around; \nTo change the camera position, hold down the right mouse button and use the WASD keys.",
            "title": "Mouse / keyboard"
        },
        {
            "location": "/tutorials/configure_the_simulation/#python-api",
            "text": "Alternatively, you can use the following code to change the view point in the server.  client = carla.Client(host, port)\nclient.get_world().get_spectator().set_transform(carla.Transform(                \n        carla.Location((x, y, z),\n        carla.Rotation(pitch, yaw, roll)))",
            "title": "Python API"
        },
        {
            "location": "/tutorials/configure_the_simulation/#camera-actor",
            "text": "If you need to frequently change the view point of SUMMIT such as tracking an vehicle, we recommend to spawn a seperate camera actor and attach it to the tracked vehicle. An example script can be found in the  expert planner repo .",
            "title": "Camera actor"
        },
        {
            "location": "/references/python_api/",
            "text": "Python API Reference\n\n\n\n\n\nImportant\n\n\nSUMMIT's Python API is an extension of CARLA's \nPython API\n. All classes and methods appearing in CARLA's Python API are accessible in SUMMIT. \n\n\nHowever, since some components were designed for different use cases, not all components from CARLA may work with SUMMIT components, and vice versa.\n\n\n\n\ncarla.Actor\n\n\nOnly additional features introduced in SUMMIT to \ncarla.Actor\n are listed here. Please refer to \nCARLA's implementation\n for the remaining original features, all of which are also accessible.\n\n\nMethods\n\n\n\n\n\nset_collision_enabled\n(\nself\n, \nenabled\n) \n\nEnable or disable collision for this instance.\n\n\nParameters:\n\n\nenabled\n: \nbool\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncarla.AABB2D\n\n\n2D axis aligned bounding box helper class.\n\n\nInstance Variables\n\n\n\n\n\n\n\nbounds_min\n (\ncarla.Vector2D\n)\n\n\n\n\n\n\nbounds_max\n (\ncarla.Vector2D\n)\n\n\n\n\n\n\nMethods\n\n\n\n\n\n\n\n__eq__\n(\nself\n, \nother\n)\n\n\n\n\nParameters:\n\n\nother\n (\ncarla.AABB2D\n)\n\n\n\n\n\n\n\n\n\n\n\n\n__ne__\n(\nself\n, \nother\n)\n\n\n\n\nParameters:\n\n\nother\n (\ncarla.AABB2D\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncarla.AABBMap\n\n\nData structure optimized for efficient collision checking of 2D axis aligned bounding boxes (AABBs).\n\n\nMethods\n\n\n\n\n\n\n\n__init__\n(\nself\n)\n\nConstructs an empty instance.\n\n\n\n\n\n\n__len__\n(\nself\n)\n\nReturns the number of AABBs contained in this instance.\n\n\n\n\n\n\ninsert\n(\nself\n, \naabb\n)\n\nInserts an AABB into this instance.\n\n\n\n\nParameters:\n\n\naabb\n (\ncarla.AABB2D\n) \n\n\n\n\n\n\n\n\n\n\n\n\nintersects\n(\nself\n, \naabb\n)\n\nChecks if an AABB intersects with any contained in this instance.\n\n\n\n\nParameters:\n\n\naabb\n (\ncarla.AABB2D\n) \n\n\n\n\n\n\nReturn:\n \nbool\n\n\n\n\n\n\n\n\n\n\ncarla.OsmLandmarks\n\n\nHelper class to load landmark meshes from OSM files.\n\n\n\n\nload\n(\nfilename\n, \noffset\n=carla.Vector2D(0, 0)\n)\n\nLoads all landmark meshes from an OSM file, applying an optional offset.\n\n\nParameters:\n\n\nfilename\n (\nstr\n) \n\n\noffset\n (\ncarla.Vector2D\n)\n\n\n\n\n\n\nReturn:\n \nlist(\ncarla.OccupancyMap\n)\n\n\n\n\n\n\n\n\n\n\ncarla.OccupancyMap\n\n\nData structure to manipulate 2D areas of occupancy.\n\n\nInstance Variables\n\n\n\n\n\nis_empty\n (\nbool\n) \n\nReturns whether this instance represents an empty area.\n\n\n\n\nMethods\n\n\n\n\n\n\n\n__init__\n(\nself\n)\n\nConstructs an instance representing an empty area.\n\n\n\n\n\n\n__init__\n(\nself\n, \nline\n, \nwidth\n)\n\nConstructs an instance representing a line buffered by some width.\n\n\n\n\nParameters:\n\n\nline\n (\nlist(\ncarla.Vector2D\n)\n)\n\n\nwidth\n (\nfloat\n)\n\n\n\n\n\n\nNote:\n \nThe buffered line has a width of \nwidth\n. Its ends are also approximately buffered round with a diameter of \nwidth\n.\n \n\n\n\n\n\n\n\n\n__init__\n(\nself\n, \npolygon\n)\n\nConstructs an instance representing a closed polygon.\n\n\n\n\nParameters:\n\n\npolygon\n (\nlist(\ncarla.Vector2D\n)\n)\n\n\n\n\n\n\nNote:\n \nPolygon vertices can be given in any orientation. Additionally, the last vertex \nshould not\n be repeated. An n-gon will require only each of the n vertices.\n\n\n\n\n\n\n\n\nload\n(\nself\n, \nfilename\n)\n\nSaves this instance to a file.\n\n\n\n\nParameters:\n\n\nfilename\n (\nstr\n)\n\n\n\n\n\n\n\n\n\n\n\n\nload\n(\nfilename\n)\n\nLoads an instance from a file.\n\n\n\n\nParameters:\n\n\nfilename\n (\nstr\n)\n\n\n\n\n\n\n\n\n\n\n\n\nunion\n(\nself\n, \nother\n)\n\nReturns the union of this instance's area and that of another instance.\n\n\n\n\nParameters:\n\n\nother\n (\ncarla.OccupancyMap\n)\n\n\n\n\n\n\nReturn:\n \ncarla.OccupancyMap\n\n\n\n\n\n\n\n\ndifference\n(\nself\n, \nother\n)\n\nReturns the difference of this instance's area and that of another instance.\n\n\n\n\nParameters:\n\n\nother\n (\ncarla.OccupancyMap\n)\n\n\n\n\n\n\nReturn:\n \ncarla.OccupancyMap\n\n\nNote:\n \nThe difference returned is the area covered by this instance that is not covered by the other instance.\n\n\n\n\n\n\n\n\nintersection\n(\nself\n, \nother\n)\n\nReturns the intersection of this instance's area and that of another instance.\n\n\n\n\nParameters:\n\n\nother\n (\ncarla.OccupancyMap\n)\n\n\n\n\n\n\nReturn:\n \ncarla.OccupancyMap\n\n\n\n\n\n\n\n\nbuffer\n(\nself\n, \nwidth\n)\n\nReturns the area formed by buffering the outlines of this instance's area by some width.\n\n\n\n\nParameters:\n\n\nwidth\n (\nfloat\n)\n\n\n\n\n\n\nReturn:\n \ncarla.OccupancyMap\n\n\nNote:\n \nThe buffered lines have a width of \nwidth\n. Ends are also approximately buffered round with a diameter of \nwidth\n.\n\n\n\n\n\n\n\n\nintersects\n(\nself\n, \nother\n)\n\nChecks if this instance's area intersects that of another instance.\n\n\n\n\nParameters:\n\n\nother\n (\ncarla.OccupancyMap\n)\n\n\n\n\n\n\nReturn:\n \nbool\n\n\n\n\n\n\n\n\ncontains\n(\nself\n, \npoint\n)\n\nChecks if a point is contained in this instance's area.\n\n\n\n\nParameters:\n\n\npoint\n (\ncarla.Vector2D\n)\n\n\n\n\n\n\nReturn:\n \nbool\n\n\n\n\n\n\n\n\ncreate_sidewalk\n(\nself\n, \ndistance\n)\n\nCreates a sidewalk along the outlines of this instance's area, with some distance away from the outlines.\n\n\n\n\nParameters:\n\n\ndistance\n (\nfloat\n)\n\n\n\n\n\n\nReturn:\n \ncarla.Sidewalk\n\n\n\n\n\n\n\n\nget_triangles\n(\nself\n) \n\nReturns the triangles in the triangulation of this instance's area.\n\n\n\n\nReturn:\n \nlist(\ncarla.Triangle2D\n)\n\n\n\n\n\n\n\n\nget_mesh_triangles\n(\nself\n, \noffset\n=0.0\n) \n\nReturns the triangles, arranged in a list of 3D vertices, in the triangulation of this instance's area with some optional added height offset.\n\n\n\n\nParameters:\n\n\noffset\n (\nfloat\n)\n\n\n\n\n\n\nReturn:\n \nlist(\ncarla.Vector3D\n)\n\n\nNote:\n \nBoth upward and downward facing triangles are produced.\n\n\n\n\n\n\n\n\nget_wall_mesh_triangles\n(\nself\n, \nheight\n=0.0\n) \n\nReturns the triangles, arranged in a list of 3D vertices, in the triangulation of the area formed by sweeping this instance's area vertically by some height.\n\n\n\n\nParameters:\n\n\nheight\n (\nfloat\n)\n\n\n\n\n\n\nReturn:\n \nlist(\ncarla.Vector3D\n)\n\n\nNote:\n \nBoth inward and outward facing triangles are produced.\n\n\n\n\n\n\n\n\n\n\ncarla.Segment2D\n\n\n2D line segment helper class.\n\n\nInstance Variables\n\n\n\n\n\n\n\nstart\n (\ncarla.Vector2D\n)\n\n\n\n\n\n\nend\n (\ncarla.Vector2D\n)\n\n\n\n\n\n\nMethods\n\n\n\n\n\n\n\n__eq__\n(\nself\n, \nother\n)\n\n\n\n\nParameters:\n\n\nother\n (\ncarla.Segment2D\n)\n\n\n\n\n\n\n\n\n\n\n\n\n__ne__\n(\nself\n, \nother\n)\n\n\n\n\nParameters:\n\n\nother\n (\ncarla.Segment2D\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncarla.SegmentMap\n\n\nRepresents a collection of line segments. Mainly used for efficiently sampling uniformly from collections of line segments.\n\n\nMethods\n\n\n\n\n\n\n\n__init__\n(\nself\n, \nsegments\n)\n\nConstructs an instance from a collection of line segments.  \n\n\n\n\nParameters:\n\n\nsegments\n (\nlist(\ncarla.Segment2D\n)\n)\n\n\n\n\n\n\n\n\n\n\n\n\nget_segments\n(\nself\n)\n\nReturns a list of all segments stored in this instance.\n\n\n\n\nReturn:\n \nlist(\ncarla.Segment2D\n)\n\n\nNote:\n \nThis operation can be time-consuming, as each segment is converted from an internal representation into a \ncarla.Segment2D\n.\n\n\n\n\n\n\n\n\nseed_rand\n(\nself\n, \nseed\n)\n\nResets this instance's internal random number generator with a seed value.\n\n\n\n\nParameters:\n\n\nseed\n (\nint\n)\n\n\n\n\n\n\n\n\n\n\n\n\nrand_point\n(\nself\n)\n\nSample a random point uniformly from this instance's segments.\n\n\n\n\nReturn:\n \ncarla.Vector2D\n\n\nNote:\n \nFirstly, a line segment is sampled with probability proportional to its length. Then, a point is uniformly picked along the selected line segment.\n\n\n\n\n\n\n\n\nunion\n(\nself\n, \nother\n)\n\nReturns a union of this instance's segments and that of another instance.\n\n\n\n\nParameters:\n\n\nother\n (\ncarla.SegmentMap\n)\n\n\n\n\n\n\nReturn:\n \ncarla.SegmentMap\n\n\n\n\n\n\n\n\ndifference\n(\nself\n, \nother\n)\n\nReturns the difference of this instance's segments and an occupancy map's area.\n\n\n\n\nParameters:\n\n\nother\n (\ncarla.OccupancyMap\n)\n\n\n\n\n\n\nReturn:\n \ncarla.SegmentMap\n\n\nNote:\n \nThe difference returned are the segments covered by this instance, cut appropriately, that are not contained in the occupancy maps' area.\n\n\n\n\n\n\n\n\nintersection\n(\nself\n, \nother\n)\n\nReturns the intersection of this instance's segments and an occupancy map's area.\n\n\n\n\nParameters:\n\n\nother\n (\ncarla.OccupancyMap\n)\n\n\n\n\n\n\nReturn:\n \ncarla.SegmentMap\n\n\n\n\n\n\n\n\n\n\ncarla.Sidewalk\n\n\nRepresents a sidewalk.\n\n\nMethods\n\n\n\n\n\n\n\nget_route_point_position\n(\nself\n, \nroute_point\n)\n\nConverts a sidewalk route point into the corresponding actual position.\n\n\n\n\nParameters:\n\n\nroute_point\n (\ncarla.SidewalkRoutePoint\n)\n\n\n\n\n\n\nReturn:\n \ncarla.Vector2D\n\n\n\n\n\n\n\n\nget_nearest_route_point\n(\nself\n, \nposition\n)\n\nDetermines the sidewalk route point closest to a position.\n\n\n\n\nParameters:\n\n\nposition\n (\ncarla.Vector2D\n)\n\n\n\n\n\n\nReturn:\n \ncarla.SidewalkRoutePoint\n\n\n\n\n\n\n\n\nget_next_route_point\n(\nself\n, \nroute_point\n, \ndistance\n)\n\nGets the next route point succeeding some route point by some distance.\n\n\n\n\nParameters:\n\n\nroute_point\n (\ncarla.SidewalkRoutePoint\n)\n\n\ndistance\n (\nfloat\n)\n\n\n\n\n\n\nReturn:\n \ncarla.SidewalkRoutePoint\n\n\nNote:\n \nThe returned route point is ahead of the given route point anticlockwise along the route point's polygon.\n\n\n\n\n\n\n\n\nget_previous_route_point\n(\nself\n, \nroute_point\n, \ndistance\n)\n\nGets the next route point preceding some route point by some distance.\n\n\n\n\nParameters:\n\n\nroute_point\n (\ncarla.SidewalkRoutePoint\n)\n\n\ndistance\n (\nfloat\n)\n\n\n\n\n\n\nReturn:\n \ncarla.SidewalkRoutePoint\n\n\nNote:\n \nThe returned route point is ahead of the given route point clockwise along the route point's polygon.\n\n\n\n\n\n\n\n\ncreate_occupancy_map\n(\nself\n, \nwidth\n)\n\nCreates an occupancy map by buffering the paths in this instance by some width.\n\n\n\n\nParameters:\n\n\nwidth\n (\nfloat\n)\n\n\n\n\n\n\nReturn:\n \ncarla.OccupancyMap\n\n\nNote:\n \nThe buffered lines have a width of \nwidth\n. Ends are also approximately buffered round with a diameter of \nwidth\n.\n\n\n\n\n\n\n\n\ncreate_segment_map\n(\nself\n)\n\nCreates a \ncarla.SegmentMap\n using the paths found in this instance.\n\n\n\n\nReturn:\n \ncarla.SegmentMap\n\n\n\n\n\n\n\n\nintersects\n(\nself\n, \nsegment\n)\n\nChecks if a line segment intersects with the paths in this instance.\n\n\n\n\nParameters:\n\n\nsegment\n (\ncarla.Segment2D\n)\n\n\n\n\n\n\nReturn:\n \nbool\n\n\n\n\n\n\n\n\n\n\ncarla.SidewalkRoutePoint\n\n\nRepresents a sidewalk route point. \n\n\nInstance Variables\n\n\n\n\n\n\n\npolygon_id\n (\nint\n)\n\n\n\n\n\n\nsegment_id\n (\nint\n)\n\n\n\n\n\n\noffset\n (\nfloat\n)\n\n\n\n\n\n\nMethods\n\n\n\n\n\n__init__\n(\nself\n)  \n\n\n\n\n\n\ncarla.SumoNetwork\n\n\nRepresents a SUMO network.\n\n\nInstance Variables\n\n\n\n\n\n\n\nbounds_min\n (\ncarla.Vector2D\n)  \n\nGets the minimum point of this instance's bounds.\n\n\n\n\n\n\nbounds_max\n (\ncarla.Vector2D\n)  \n\nGets the maximum point of this instance's bounds.\n\n\n\n\n\n\noriginal_bounds_min\n (\ncarla.Vector2D\n)  \n\nGets the minimum point (in LatLon) of this instance's geographic bounds.\n\n\n\n\n\n\noriginal_bounds_max\n (\ncarla.Vector2D\n)  \n\nGets the maximum point (in LatLon) of this instance's geographic bounds.\n\n\n\n\n\n\noffset\n (\ncarla.Vector2D\n)   \n\nGets the offset applied to the SUMO network to move it to the origin.\n\n\n\n\n\n\nMethods\n\n\n\n\n\n\n\nget_route_point_position\n(\nself\n, \nroute_point\n)\n\nConverts a SUMO network route point into the corresponding actual position.\n\n\n\n\nParameters:\n\n\nroute_point\n (\ncarla.SumoNetworkRoutePoint\n)\n\n\n\n\n\n\nReturn:\n \ncarla.Vector2D\n\n\n\n\n\n\n\n\nget_nearest_route_point\n(\nself\n, \nposition\n)\n\nDetermines the SUMO network route point closest to a position.\n\n\n\n\nParameters:\n\n\nposition\n (\ncarla.Vector2D\n)\n\n\n\n\n\n\nReturn:\n \ncarla.SumoNetworkRoutePoint\n\n\n\n\n\n\n\n\nget_next_route_points\n(\nself\n, \nroute_point\n, \ndistance\n)\n\nGets the list of possible next route points succeeding some route point by some distance.\n\n\n\n\nParameters:\n\n\nroute_point\n (\ncarla.SumoNetworkRoutePoint\n)\n\n\ndistance\n (\nfloat\n)\n\n\n\n\n\n\nReturn:\n \nlist(\ncarla.SumoNetworkRoutePoint\n)\n\n\n\n\n\n\n\n\nget_next_route_paths\n(\nself\n, \nroute_point\n, \nnum_points\n, \ninterval\n)\n\nGets the list of possible paths succeeding some route point. Each path spans a specified number of points with some given interval.\n\n\n\n\nParameters:\n\n\nroute_point\n (\ncarla.SumoNetworkRoutePoint\n)\n\n\nnum_points\n (\nint\n)\n\n\ninterval\n (\nfloat\n)\n\n\n\n\n\n\nReturn:\n \nlist(list(\ncarla.SumoNetworkRoutePoint\n))\n\n\n\n\n\n\n\n\ncreate_occupancy_map\n(\nself\n)\n\nCreates the occupancy map for this instance.\n\n\n\n\nReturn:\n \ncarla.OccupancyMap\n\n\n\n\n\n\n\n\ncreate_roadmark_occupancy_map\n(\nself\n)\n\nCreates the occupancy map for this instance's roadmarks.\n\n\n\n\nReturn:\n \ncarla.OccupancyMap\n\n\n\n\n\n\n\n\ncreate_segment_map\n(\nself\n)\n\nCreates a \ncarla.SegmentMap\n using the lanes found in this instance.\n\n\n\n\nReturn:\n \ncarla.SegmentMap\n\n\n\n\n\n\n\n\n\n\ncarla.SumoNetworkRoutePoint\n\n\nRepresents a SUMO network route point. \n\n\nInstance Variables\n\n\n\n\n\nedge\n (\nstr\n)\n\n\nlane\n (\nint\n)\n\n\nsegment\n (\nint\n)\n\n\noffset\n (\nfloat\n)\n\n\n\n\nMethods\n\n\n\n\n\n__init__\n(\nself\n)  \n\n\n\n\n\n\ncarla.Triangle2D\n\n\n2D triangle helper class.\n\n\nInstance Variables\n\n\n\n\n\n\n\nv0\n (\ncarla.Vector2D\n)\n\n\n\n\n\n\nv1\n (\ncarla.Vector2D\n)\n\n\n\n\n\n\nv2\n (\ncarla.Vector2D\n)\n\n\n\n\n\n\nMethods\n\n\n\n\n\n\n\n__eq__\n(\nself\n, \nother\n)\n\n\n\n\nParameters:\n\n\nother\n (\ncarla.Triangle2D\n)\n\n\n\n\n\n\n\n\n\n\n\n\n__ne__\n(\nself\n, \nother\n)\n\n\n\n\nParameters:\n\n\nother\n (\ncarla.Triangle2D\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncarla.Vector2D\n\n\nOnly additional features introduced in SUMMIT to \ncarla.Vector2D\n are listed here. Please refer to \nCARLA's implementation\n for the remaining original features, all of which are also accessible.\n\n\nMethods\n\n\n\n\n\n\n\nsquared_length\n(\nself\n)  \n\nReturns the squared length of this instance.\n\n\n\n\nReturn:\n \nfloat\n\n\n\n\n\n\n\n\nlength\n(\nself\n)  \n\nReturns the length of this instance.\n\n\n\n\nReturn:\n \nfloat\n\n\n\n\n\n\n\n\nmake_unit_vector\n(\nself\n)  \n\nReturns the unit vector of this instance.\n\n\n\n\nReturn:\n \ncarla.Vector2D\n\n\n\n\n\n\n\n\nrotate\n(\nself\n, \nangle\n)  \n\nReturns the result of rotating this instance by an angle.\n\n\n\n\nParameters:\n\n\nangle\n: (\nfloat\n) (in radians)\n\n\n\n\n\n\nReturn:\n \ncarla.Vector2D\n\n\n\n\n\n\n\n\ndot_product\n(\nvector1\n, \nvector2\n)  \n\nReturns the dot product of two vectors.\n\n\n\n\nParameters:\n\n\nvector1\n: (\ncarla.Vector2D\n)\n\n\nvector2\n: (\ncarla.Vector2D\n)\n\n\n\n\n\n\nReturn:\n \nfloat\n\n\n\n\n\n\n\n\n\n\ncarla.World\n\n\nOnly additional features introduced in SUMMIT to \ncarla.World\n are listed here. Please refer to \nCARLA's implementation\n for the remaining original features, all of which are also accessible.\n\n\nMethods\n\n\n\n\n\n\n\nspawn_dynamic_mesh\n(\nself\n, \ntriangles\n, \nmaterial\n, \nsegmentation_tag\n)  \n\nSpawns a dynamic mesh using mesh triangles, together with a specified material and \nsegmentation tag\n. Returns the id of the spawned dynamic mesh (note: these ids are \nnot\n the same as actor ids).\n\n\n\n\nParameters:\n\n\ntriangles\n: \nlist(\ncarla.Vector3D\n)\n\n\nmaterial\n: \nstr\n \n\n\nsegmentation_tag\n: \nint\n\n\n\n\n\n\nReturn:\n \nint\n\n\n\n\n\n\n\n\nspawn_dynamic_tile_mesh\n(\nself\n, \nbounds_min\n, \nbounds_max\n, \ndata\n, \nsegmentation_tag\n)  \n\nSpawns a rectangular dynamic mesh of a JPEG image \nsegmentation tag\n. Returns the id of the spawned dynamic mesh (note: these ids are \nnot\n the same as actor ids).\n\n\n\n\nParameters:\n\n\nbounds_min\n: \ncarla.Vector3D\n\n\nbounds_max\n: \ncarla.Vector3D\n\n\ndata\n: \nlist(int)\n - The JPEG data, as an array of bytes. \n\n\nsegmentation_tag\n: \nint\n\n\n\n\n\n\nReturn:\n \nint\n\n\n\n\n\n\n\n\ndestroy_dynamic_mesh\n(\nself\n, \nid\n)  \n\nDestroys a dynamic mesh given its id. Returns whether the operation succeeded.\n\n\n\n\nParameters:\n\n\nid\n: \nint\n\n\n\n\n\n\nReturn:\n \nbool\n\n\n\n\n\n\n\n\n\n\ncommand.SpawnDynamicMesh\n\n\nSpawns a dynamic mesh out of mesh triangles.\n\n\nInstance Variables\n\n\n\n\n\ntriangles\n (\nlist(\ncarla.Triangle2D\n)\n)\n\n\nmaterial\n (\nstr\n)\n\n\nsemantic_tag\n (\nint\n)\n\n\n\n\nMethods\n\n\n\n\n\n__init__\n(\ntriangles\n, \nmaterial\n, \nsegmentation_tag\n)    \n\n\nParameters:\n\n\ntriangles\n: \nlist(\ncarla.Vector3D\n)\n\n\nmaterial\n: \nstr\n \n\n\nsegmentation_tag\n: \nint\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncommand.DestroyDynamicMesh\n\n\nDestroys a dynamic mesh given its id.\n\n\nInstance Variables\n\n\n\n\n\nid\n (\nint\n)\n\n\n\n\nMethods\n\n\n\n\n\n__init__\n(\nid\n)    \n\n\nParameters:\n\n\nid\n: \nint",
            "title": "Python API reference"
        },
        {
            "location": "/references/python_api/#carlaactor",
            "text": "Only additional features introduced in SUMMIT to  carla.Actor  are listed here. Please refer to  CARLA's implementation  for the remaining original features, all of which are also accessible.",
            "title": "carla.Actor"
        },
        {
            "location": "/references/python_api/#carlaaabb2d",
            "text": "2D axis aligned bounding box helper class.",
            "title": "carla.AABB2D"
        },
        {
            "location": "/references/python_api/#carlaaabbmap",
            "text": "Data structure optimized for efficient collision checking of 2D axis aligned bounding boxes (AABBs).",
            "title": "carla.AABBMap"
        },
        {
            "location": "/references/python_api/#carlaosmlandmarks",
            "text": "Helper class to load landmark meshes from OSM files.   load ( filename ,  offset =carla.Vector2D(0, 0) ) \nLoads all landmark meshes from an OSM file, applying an optional offset.  Parameters:  filename  ( str )   offset  ( carla.Vector2D )    Return:   list( carla.OccupancyMap )",
            "title": "carla.OsmLandmarks"
        },
        {
            "location": "/references/python_api/#carlaoccupancymap",
            "text": "Data structure to manipulate 2D areas of occupancy.",
            "title": "carla.OccupancyMap"
        },
        {
            "location": "/references/python_api/#carlasegment2d",
            "text": "2D line segment helper class.",
            "title": "carla.Segment2D"
        },
        {
            "location": "/references/python_api/#carlasegmentmap",
            "text": "Represents a collection of line segments. Mainly used for efficiently sampling uniformly from collections of line segments.",
            "title": "carla.SegmentMap"
        },
        {
            "location": "/references/python_api/#carlasidewalk",
            "text": "Represents a sidewalk.",
            "title": "carla.Sidewalk"
        },
        {
            "location": "/references/python_api/#carlasidewalkroutepoint",
            "text": "Represents a sidewalk route point.",
            "title": "carla.SidewalkRoutePoint"
        },
        {
            "location": "/references/python_api/#carlasumonetwork",
            "text": "Represents a SUMO network.",
            "title": "carla.SumoNetwork"
        },
        {
            "location": "/references/python_api/#carlasumonetworkroutepoint",
            "text": "Represents a SUMO network route point.",
            "title": "carla.SumoNetworkRoutePoint"
        },
        {
            "location": "/references/python_api/#carlatriangle2d",
            "text": "2D triangle helper class.",
            "title": "carla.Triangle2D"
        },
        {
            "location": "/references/python_api/#carlavector2d",
            "text": "Only additional features introduced in SUMMIT to  carla.Vector2D  are listed here. Please refer to  CARLA's implementation  for the remaining original features, all of which are also accessible.",
            "title": "carla.Vector2D"
        },
        {
            "location": "/references/python_api/#carlaworld",
            "text": "Only additional features introduced in SUMMIT to  carla.World  are listed here. Please refer to  CARLA's implementation  for the remaining original features, all of which are also accessible.",
            "title": "carla.World"
        },
        {
            "location": "/references/python_api/#commandspawndynamicmesh",
            "text": "Spawns a dynamic mesh out of mesh triangles.",
            "title": "command.SpawnDynamicMesh"
        },
        {
            "location": "/references/python_api/#commanddestroydynamicmesh",
            "text": "Destroys a dynamic mesh given its id.",
            "title": "command.DestroyDynamicMesh"
        },
        {
            "location": "/references/summit_map_library/",
            "text": "SUMMIT Map Library \n\n\n\nThis page lists all available maps built into SUMMIT that are ready for use. These maps are all extracted from real locations in the world.\n\n\nbeijing\n\n\n\n\n\n\nIdentifier: \nbeijing\n\n\nType: Highway\n\n\nLocation: \nChao Yang Men Bei Da Jie. Beijing, China\n\n\n\n\n\n\nchandni_chowk\n\n\n\n\n\n\nIdentifier: \nchandni_chowk\n\n\nDescription: Roundabout\n\n\nLocation: \nBhai Mati Das Chowk. New Delhi, India\n\n\n\n\n\n\nhighway\n\n\n\n\n\n\nIdentifier: \nhighway\n\n\nType: Highway\n\n\nLocation: \nAyer Rajah Expressway. Singapore\n \n\n\n\n\n\n\nmagic\n\n\n\n\n\n\nIdentifier: \nmagic\n\n\nType: Roundabout\n\n\nLocation: \nThe Magic Roundabout. Swindon, United Kingdom\n\n\n\n\n\n\nmeskel_square\n\n\n\n\n\n\nIdentifier: \nmeskel_square\n\n\nType: Intersection\n\n\nLocation: \nMeskel Square. Addis Ababa, Ethiopia\n\n\n\n\n\n\nshi_men_er_lu\n\n\n\n\n\n\nIdentifier: \nshi_men_er_lu\n\n\nType: Intersection\n\n\nLocation: \nShi Men Er Lu. Shanghai, China\n\n\n\n\n\n\nshibuya\n\n\n\n\n\n\nIdentifier: \nshibuya\n\n\nType: Intersection\n\n\nLocation: \nShibuya Crossing. Tokyo, Japan",
            "title": "SUMMIT map library"
        },
        {
            "location": "/references/summit_map_library/#beijing",
            "text": "Identifier:  beijing  Type: Highway  Location:  Chao Yang Men Bei Da Jie. Beijing, China",
            "title": "beijing"
        },
        {
            "location": "/references/summit_map_library/#chandni95chowk",
            "text": "Identifier:  chandni_chowk  Description: Roundabout  Location:  Bhai Mati Das Chowk. New Delhi, India",
            "title": "chandni_chowk"
        },
        {
            "location": "/references/summit_map_library/#highway",
            "text": "Identifier:  highway  Type: Highway  Location:  Ayer Rajah Expressway. Singapore",
            "title": "highway"
        },
        {
            "location": "/references/summit_map_library/#magic",
            "text": "Identifier:  magic  Type: Roundabout  Location:  The Magic Roundabout. Swindon, United Kingdom",
            "title": "magic"
        },
        {
            "location": "/references/summit_map_library/#meskel95square",
            "text": "Identifier:  meskel_square  Type: Intersection  Location:  Meskel Square. Addis Ababa, Ethiopia",
            "title": "meskel_square"
        },
        {
            "location": "/references/summit_map_library/#shi95men95er95lu",
            "text": "Identifier:  shi_men_er_lu  Type: Intersection  Location:  Shi Men Er Lu. Shanghai, China",
            "title": "shi_men_er_lu"
        },
        {
            "location": "/references/summit_map_library/#shibuya",
            "text": "Identifier:  shibuya  Type: Intersection  Location:  Shibuya Crossing. Tokyo, Japan",
            "title": "shibuya"
        },
        {
            "location": "/references/releases/",
            "text": "SUMMIT Releases + Downloads\n\n\n\nEach version of SUMMIT is matched with that of CARLA. For example, SUMMIT version 0.9.8 includes all the CARLA features up to CARLA version 0.9.8.\n\n\nIn order to speed up downloads, the \nlite\n versions exclude a significant amount of CARLA assets that you probably won't need to run SUMMIT. If you need access to all CARLA assets, please download the \nnon-lite\n versions.\n\n\n\n\n\n0.9.8e\n [\ndownload lite\n] [\ndownload non-lite\n]\n\n\n\n\nCompatible with Python 2.7 and Python 3.6.\n\n\nFixed lighting problems.\n\n\n\n\n0.9.8d\n [\ndownload lite\n] [\ndownload non-lite\n]\n\n\n\n\nCompatible with Python 2.7 and Python 3.6.\n\n\nMinor tweaks in traffic controller.\n\n\n\n\n0.9.8c\n [\ndownload lite\n] [\ndownload non-lite\n]\n\n\n\n\nCompatible with Python 2.7 and Python 3.6.\n\n\nVarious tweaks and bug fixes in traffic controller.\n\n\nBug fixes to landmarks extraction.\n\n\n\n\n0.9.8b\n [\ndownload lite\n] [\ndownload non-lite\n]\n\n\n\n\nCompatible with Python 2.7 and Python 3.6.\n\n\nMinor edit to \nspawn_meshes.py\n to change camera position after spawning map objects.\n\n\nMinor cleanup of redundant files.\n\n\n\n\n0.9.8\n [\ndownload non-lite\n]\n\n\n\n\nCompatible with Python 2.7 and Python 3.6.\n\n\nInitial public release of SUMMIT.",
            "title": "SUMMIT releases + downloads"
        }
    ]
}